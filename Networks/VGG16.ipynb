{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ',\n",
       " '',\n",
       " 'C:\\\\Users\\\\Joelr\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\Joelr\\\\Anaconda3\\\\envs\\\\tf_EPQ\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\Joelr\\\\.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import layers, preprocessing, callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "import datetime, os\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important variables\n",
    "EPOCHS = 50\n",
    "\n",
    "TRAIN_DIR = \"C:/Users\\Joelr/Keras_EPQ/x_rays/train\"\n",
    "TEST_DIR = \"C:/Users\\Joelr/Keras_EPQ/x_rays/test\"\n",
    "PRED_DIR = \"C:/Users/Joelr/Keras_EPQ/x_rays/prediction\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "CLASSES = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7392 images belonging to 5 classes.\n",
      "Found 462 images belonging to 5 classes.\n",
      "Found 18 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2 3 4], y=[0 0 0 ... 4 4 4] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=2.0,\n",
    "    height_shift_range=2.0,\n",
    "    zoom_range=0.125,\n",
    "    channel_shift_range=0.0, #was 3.0\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_data_gen = train_gen.flow_from_directory(directory= TRAIN_DIR,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = CLASSES)\n",
    "\n",
    "test_data_gen = test_gen.flow_from_directory(directory= TEST_DIR,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = CLASSES)\n",
    "\n",
    "\n",
    "pred_data_gen = test_gen.flow_from_directory(directory= PRED_DIR,\n",
    "                                                     batch_size= 18 ,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     classes = \"0\")\n",
    "\n",
    "\n",
    " \n",
    "# Alter class weights to to counter imbalance\n",
    "\n",
    "weight = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_data_gen.classes), \n",
    "                train_data_gen.classes)\n",
    "\n",
    "CLASS_WEIGHTS = dict(enumerate(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "base = VGG16(weights='imagenet', include_top=False,input_tensor=Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
    "\n",
    "# Take output from pre-trained and put through custom classifier\n",
    "x = base.output\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "x =tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x =tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x =tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x) #OUtput is an array of probabilities 0-1\n",
    "\n",
    "model = Model(inputs=base.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n",
      "19 global_max_pooling2d\n",
      "20 dense\n",
      "21 dense_1\n",
      "22 dense_2\n",
      "23 dense_3\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 15,797,957\n",
      "Trainable params: 15,797,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Select which layers to train\n",
    "for layer in model.layers[:10]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[10:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "#model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"testVGG16.h5\",include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/462 [..............................] - ETA: 0s - loss: 2.0037 - acc: 0.1250WARNING:tensorflow:From c:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "462/462 [==============================] - 99s 215ms/step - loss: 1.6280 - acc: 0.1292 - val_loss: 1.6096 - val_acc: 0.1342\n",
      "Epoch 2/50\n",
      "462/462 [==============================] - 96s 208ms/step - loss: 1.6097 - acc: 0.1909 - val_loss: 1.6096 - val_acc: 0.1342\n",
      "Epoch 3/50\n",
      "462/462 [==============================] - 96s 208ms/step - loss: 1.6098 - acc: 0.1350 - val_loss: 1.6093 - val_acc: 0.2165\n",
      "Epoch 4/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6097 - acc: 0.2545\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "462/462 [==============================] - 96s 209ms/step - loss: 1.6097 - acc: 0.2545 - val_loss: 1.6099 - val_acc: 0.1342\n",
      "Epoch 5/50\n",
      "462/462 [==============================] - 96s 208ms/step - loss: 1.6095 - acc: 0.0353 - val_loss: 1.6098 - val_acc: 0.1342\n",
      "Epoch 6/50\n",
      "462/462 [==============================] - 96s 208ms/step - loss: 1.6095 - acc: 0.0331 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 7/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6095 - acc: 0.0292\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "462/462 [==============================] - 97s 210ms/step - loss: 1.6095 - acc: 0.0292 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 8/50\n",
      "462/462 [==============================] - 102s 220ms/step - loss: 1.6095 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 9/50\n",
      "462/462 [==============================] - 139s 301ms/step - loss: 1.6095 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 10/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6095 - acc: 0.0295\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "462/462 [==============================] - 147s 319ms/step - loss: 1.6095 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 11/50\n",
      "462/462 [==============================] - 149s 322ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 12/50\n",
      "462/462 [==============================] - 149s 322ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 13/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "462/462 [==============================] - 147s 319ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 14/50\n",
      "462/462 [==============================] - 148s 319ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 15/50\n",
      "462/462 [==============================] - 121s 261ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 16/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "462/462 [==============================] - 104s 225ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 17/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 18/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 19/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 20/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 21/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 22/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 23/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 24/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 25/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 26/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 27/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 28/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 29/50\n",
      "462/462 [==============================] - 107s 231ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 30/50\n",
      "462/462 [==============================] - 106s 230ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 31/50\n",
      "462/462 [==============================] - ETA: 0s - loss: 1.6094 - acc: 0.0295\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
      "462/462 [==============================] - 107s 231ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 32/50\n",
      "462/462 [==============================] - 107s 231ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 33/50\n",
      "462/462 [==============================] - 107s 231ms/step - loss: 1.6094 - acc: 0.0295 - val_loss: 1.6097 - val_acc: 0.1342\n",
      "Epoch 34/50\n",
      "426/462 [==========================>...] - ETA: 7s - loss: 1.6135 - acc: 0.0299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-27680bc79d63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m          \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m           \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLASS_WEIGHTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m          )\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\joelr\\anaconda3\\envs\\gamer\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1,  write_graph=True)\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3,\n",
    "                              min_lr=0,\n",
    "                              cooldown=0,\n",
    "                              min_delta=0.001,\n",
    "                              verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.1,\n",
    "    patience=15,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "callbacks = [tensorboard_callback, reduce_lr]\n",
    "\n",
    "model.fit(x = train_data_gen,\n",
    "         epochs = EPOCHS,\n",
    "         validation_data = test_data_gen,\n",
    "          callbacks=callbacks,\n",
    "          class_weight = CLASS_WEIGHTS\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"VGG16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_array = model.predict(test_data_gen)\n",
    "preds = np.argmax(preds_array, axis=1)\n",
    "\n",
    "conf_mat = confusion_matrix(test_data_gen.classes, preds)\n",
    "print('Confusion Matrix')\n",
    "print(conf_mat,\"\\n\")\n",
    "print('Classification Report')\n",
    "print(classification_report(test_data_gen.classes, preds, target_names=CLASSES))\n",
    "\n",
    "# Precision = True Positives / True Positives + False Positives i.e. Out of all the knees labelled as 4, how many were actually 4\n",
    "# Recall = True Pos / True pos + False neg i.e. Out of all the knees that were actually 4, how many were labelled 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of confusion matrix\n",
    "\n",
    "%matplotlib\n",
    "sn.heatmap(conf_mat, annot=True, \n",
    "            fmt='', cmap='Blues')\n",
    "\n",
    "\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "b, t = plt.ylim()\n",
    "b += 0.5 \n",
    "t -= 0.5 \n",
    "plt.ylim(b, t)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Gives % confidence predictions and shows on bar chart.\n",
    "x, y = test_data_gen.next()\n",
    "pred_array = model.predict(x)\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    \n",
    "    ax1.imshow(x[i])\n",
    "    label = \"True Class \" + str(y[i] )\n",
    "    ax1.set_xlabel(label)\n",
    "\n",
    "    ax2.bar(CLASSES, pred_array[i]*100, width=0.8, bottom=None, align='center', data=None)\n",
    "    ax2.set_ylim([0,100])\n",
    "    ax2.set_ylabel('Prediction Confidence(%)')\n",
    "    ax2.set_xlabel(\"Classes\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad CAM from https://keras.io/examples/vision/grad_cam/#the-gradcam-algorithm\n",
    "\n",
    "img_size = (150, 150)\n",
    "\n",
    "last_conv_layer_name = \"block5_conv3\"\n",
    "\n",
    "classifier_layer_names = [\n",
    "    \"global_max_pooling2d\",\n",
    "    \"dense\",\n",
    "    \"dense_1\",\n",
    "    \"dense_2\",\n",
    "    \"dense_3\"\n",
    "]\n",
    "\n",
    "img_path = \"C://Users//Joelr//Keras_EPQ//x_rays//test//2//9024940R.png\"\n",
    "\n",
    "\n",
    "display(Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad CAM from https://keras.io/examples/vision/grad_cam/#the-gradcam-algorithm\n",
    "\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    # `img` is a PIL image of size 299x299\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
    "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    # We add a dimension to transform our array into a \"batch\"\n",
    "    # of size (1, 299, 299, 3)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad CAM from https://keras.io/examples/vision/grad_cam/#the-gradcam-algorithm\n",
    "\n",
    "\n",
    "img_array = get_img_array(img_path, size=img_size)\n",
    "\n",
    "# Make model\n",
    "\n",
    "# Print what the top predicted class is\n",
    "preds = model.predict(img_array)\n",
    "print(\"Predicted:\",np.argmax(preds[0]))\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    ")\n",
    "\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad CAM from https://keras.io/examples/vision/grad_cam/#the-gradcam-algorithm\n",
    "\n",
    "def CAM(img_path):\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "    \n",
    "    img_array = get_img_array(img_path, size=img_size)\n",
    "    \n",
    "    preds = model.predict(img_array)\n",
    "    print(\"Predicted:\",np.argmax(preds[0]))\n",
    "    \n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names)\n",
    "\n",
    "    # We rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * 0.4 + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    save_path = \"C:/Users/Joelr/Keras_EPQ/CAM/vgg16/\" + img_path[37] + \"/\" + img_path[39:]\n",
    "    superimposed_img.save(save_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont use this a lot\n",
    "\n",
    "from os import listdir\n",
    "import fnmatch\n",
    "\n",
    "folders = os.listdir(\"C:/Users/Joelr/Keras_EPQ/x_rays/test\")\n",
    "\n",
    "\n",
    "import glob\n",
    "files = glob.glob(\"C:/Users/Joelr/Keras_EPQ/x_rays/test/0/*.png\")\n",
    "\n",
    "# 37 index for class  39 index onwards for name\n",
    "\n",
    "for file in files:\n",
    "    CAM(file)\n",
    "    #print(files[file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
